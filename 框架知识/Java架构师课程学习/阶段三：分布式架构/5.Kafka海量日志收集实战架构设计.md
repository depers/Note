## 5. Kafka海量日志收集实战架构设计

### 1-1 本章导航

* Kafka核心概念、设计、应用场景
* Kafka环境搭建、急速入门
* 与Spring Boot整合实战
* Kafka高吞吐量核心实战
  * 日志收集设计
  * 日志输出（日志组件输出log4j2）
  * 日志收集（FileBeat）
  * 日志过滤（logstash）
  * 日志持久化（elasticsearch）
  * 日志可视化（kibana）
* 分布式日志收集、链路追踪、监控告警平台架构讲解

### 1-4 Kafka与springboot整合_生产者讲解

1. 新建项目：mall-kafka，包含两个子项目：kafka-producer和kafka-consumer。本节主要介绍kafka-producer。

2. 配置mall-kafka项目pom

3. 配置kafka-producer的application.properties文件

   这里涉及到了一个kafka的核心配置，kafka生产端消息确认（持久化）配置

   ```properties
   # acks=0：生产者在成功写入消息之前不会等待任何来自服务器的响应。不做任何等待，把消息发送过去就完了
   # acks=1（推荐）：只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应，生产者就认为消息投递成功了
   # acks=-1：表示分区leader必须等待消息被成功写入到所有的ISR副本(同步副本)中才认为producer请求成功。这种方案提供最高的消息持久性保证，但是理论上吞吐率也是最差的。
   # 这个配置可以参考：https://blog.csdn.net/zp17834994071/article/details/108113578
   ## 	这个是kafka生产端最重要的选项
   spring.kafka.producer.acks=1
   ```

   上面有几个概念需要我声明一下：

   * 分区leader：一个分区里面会有多个副本（replica，或者是Follower）和一个从副本中选举的leader
   * 分区：Partition
   * ISR副本：ISR(In-Sync Replica)：是Replicas的一个子集，表示目前Alive且与Leader能够“Catch-up”的Replicas集合。也就是保持同步的副本，他的含义就是，跟Leader始终保持同步的Follower有哪些。

   下面是我对以上三个配置的理解：

   * acks=0：生产者直接发就行，不管消息是否同步完成。
   * acks=1：只要Partition Leader接收到消息而且写入本地磁盘了，就认为成功了。leader就会发确认应答。
   * acks=-1：Partition Leader接收到消息之后，还必须要求ISR列表里跟Leader保持同步的那些Follower都要把消息同步过去，才能认为这条消息是写入成功了。

4. 编写kafka发送消息的service：cn.bravedawn.kafka.producer.KafkaProducerService

### 1-5 Kafka与springboot整合_消费者讲解

1. 编辑kafka-consumer的application.properties：kafka-consumer/src/main/resources/application.properties

2. 编辑消息消费者：cn.bravedawn.kafka.consumer.KafkaConsumerService

3. 通过以下命令对Kafka的topic和partition进行查看和操作：

   * 创建topic主题命令（创建名为test的topic， 1个分区分别存放数据，数据备份总共1份）：

     ```shell
     ./kafka-topics.sh --zookeeper 192.168.156.135:2181 --create --topic test --partitions 1 --replication-factor 1
     
     ## --zookeeper 为zk服务列表
     ## --create 命令后 --topic 为创建topic 并指定 topic name
     ## --partitions 为指定分区数量
     ## --replication-factor 为指定副本集数量
     ```

   * 查看topic列表命令：

     ```shell
     ./kafka-topics.sh --zookeeper 192.168.156.135:2181 --list
     ```

   * kafka查看消费进度：（当我们需要查看一个消费者组的消费进度时，则使用下面的命令。注意运行该命令之前先运行mall-consumer创建group）

     ```shell
     ./kafka-consumer-groups.sh --bootstrap-server 192.168.156.135:9092 --describe --group group01
     
     ## --bootstrap-server 连接的kafka服务器
     ## --describe 展示
     ## --group 指定客户端监听的群组id
     ```

     

   

   



